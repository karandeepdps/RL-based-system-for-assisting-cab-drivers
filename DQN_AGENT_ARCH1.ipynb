{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cab drivers, like most people, are incentivised by a healthy growth in income. The goal of your project is to build an RL-based algorithm which can help cab drivers maximise their profits by improving their decision-making process on the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters\n",
    "m = 5 # number of cities, ranges from 1 ..... m\n",
    "t = 24 # number of hours, ranges from 0 .... t-1\n",
    "d = 7  # number of days, ranges from 0 ... d-1\n",
    "C = 5 # Per kilometer fuel and other costs\n",
    "R = 9 # per kilometer revenue from a passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(r\"C:\\Users\\rashi\\Downloads\\RL car project\\TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking Q-value convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_track = collections.defaultdict(dict)\n",
    "def initialise_tracking_states():\n",
    "    sample_q_values = [((3,0,2),(3,1)),((1,6,3),(2,3)),((2,2,2),(3,2)),((3,10,6),(3,4)),((0,20,3),(1,4)), ((1,23,3),(1,4))]    #select any 4 Q-values\n",
    "    for q_values in sample_q_values:\n",
    "        state = q_values[0]\n",
    "        action = q_values[1]\n",
    "        states_track[state][action] = []    #this is an array which will have appended values of that state-action pair for every 2000th episode         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialise_tracking_states() # initialised all the state-action pairs tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will append latest Q-values of the 6 Q-values which are being tracked for checking convergence\n",
    "\n",
    "def save_tracking_states():\n",
    "    for state in states_track.keys():\n",
    "        for action in states_track[state].keys():\n",
    "            state_encod = env.state_encod_arch1(state)\n",
    "            state_encod = np.reshape(state_encod, [1, agent.state_size])\n",
    "            prediction = agent.model.predict(state_encod)\n",
    "            action_list = list(action)\n",
    "            #print(\"Action\", action_list)\n",
    "            action_idx = env.action_space.index(action_list)\n",
    "            #print(\"Action index\", action_idx)\n",
    "            Q = prediction[0][action_idx]\n",
    "            #print(\"Q\", Q)\n",
    "            states_track[state][action].append(Q)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the object as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Agent Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "\n",
    "        # Define size of state and action\n",
    "        self.state_size = m+t+d \n",
    "        self.action_size = m*(m-1) + 1\n",
    "        self.action_space = [[i,j] for i in range(m) for j in range(m) if i!=j or i==0]\n",
    "\n",
    "        # These are hyper parameters for the DQN\n",
    "        self.discount_factor = 0.95\n",
    "        self.learning_rate = 0.001        \n",
    "        self.epsilon_max = 1.0\n",
    "        self.epsilon_decay = 0.0003\n",
    "        self.epsilon_min = 0.00000001\n",
    "        \n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        \n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(200, input_dim = self.state_size,activation ='relu'))\n",
    "        model.add(Dense(150,activation ='relu'))\n",
    "        model.add(Dense(100,activation ='relu'))\n",
    "        model.add(Dense(self.action_size,activation ='linear'))\n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state, episode):\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in ε after we generate each sample from the environment\n",
    "        poss_actions_idx, poss_actions = env.requests(state)\n",
    "        epsilon = self.epsilon_min + (self.epsilon_max - self.epsilon_min) * np.exp(-self.epsilon_decay*episode)\n",
    "        \n",
    "    \n",
    "        if np.random.rand() <= epsilon: # Exploration: randomly choosing and action      \n",
    "            action_idx = np.random.choice(poss_actions_idx)\n",
    "            action = self.action_space[action_idx]\n",
    "        else: #Exploitation: this gets the action corresponding to max q-value of current state\n",
    "            state_encod = env.state_encod_arch1(state)\n",
    "            state_encod = np.reshape(state_encod, [1, self.state_size])\n",
    "            q_value = self.model.predict(state_encod)\n",
    "            q_value = q_value[0][poss_actions_idx]\n",
    "            action_idx = np.argmax(q_value)\n",
    "            action = poss_actions[action_idx]\n",
    "            \n",
    "        return action, epsilon\n",
    "        \n",
    "        \n",
    "    # save sample <s,a,r,s'> to the replay memory \n",
    "    def append_sample(self, state, action, reward, next_state, terminal_state):\n",
    "        self.memory.append((state, action, reward, next_state, terminal_state))\n",
    "    \n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "  \n",
    "\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        # Sample batch from the memory\n",
    "        mini_batch = random.sample(self.memory, self.batch_size)\n",
    "        update_output = np.zeros((self.batch_size, self.state_size))\n",
    "        update_input = np.zeros((self.batch_size, self.state_size))\n",
    "\n",
    "        actions, rewards, terminal_states = [], [], []\n",
    "\n",
    "        \n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            \n",
    "            state, action, reward, next_state, terminal_state = mini_batch[i]\n",
    "            \n",
    "            actions.append(self.action_space.index(action))\n",
    "            rewards.append(reward)\n",
    "            terminal_states.append(terminal_state)\n",
    "            \n",
    "\n",
    "            update_input[i] = env.state_encod_arch1(state)\n",
    "            update_output[i] = env.state_encod_arch1(next_state)\n",
    "                \n",
    "        target = self.model.predict(update_input)\n",
    "        target_val = self.model.predict(update_output)\n",
    "        \n",
    "        # get your target Q-value on the basis of terminal state\n",
    "        for i in range(self.batch_size):\n",
    "            if terminal_states[i]:\n",
    "                #print(True)\n",
    "                target[i][actions[i]] = rewards[i]\n",
    "                \n",
    "            else:\n",
    "                target[i][actions[i]] = rewards[i] + self.discount_factor * (np.amax(target_val[i]))\n",
    "\n",
    "        self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "\n",
    "                \n",
    "                \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "        \n",
    "                    \n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the environment\n",
    "env = CabDriver()\n",
    "# get size of state and action from environment\n",
    "state_size = len(env.state_space)\n",
    "action_size = len(env.action_space)\n",
    "\n",
    "# agent needs to be initialised outside the loop since the DQN\n",
    "# network will be initialised along with the agent\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "# tracking average reward per episode = total rewards in an episode/ total steps in an episode\n",
    "avg_reward = []\n",
    "\n",
    "# tracking total rewards per episode\n",
    "total_reward  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 124.0   memory length: 148   epsilon: 1.0\n",
      "episode: 25   score: -246.0   memory length: 2000   epsilon: 0.9925280548938579\n",
      "episode: 50   score: -101.0   memory length: 2000   epsilon: 0.9851119397519432\n",
      "episode: 75   score: 156.0   memory length: 2000   epsilon: 0.9777512374158239\n",
      "episode: 100   score: -50.0   memory length: 2000   epsilon: 0.9704455338440529\n",
      "episode: 125   score: -199.0   memory length: 2000   epsilon: 0.9631944180888776\n",
      "episode: 150   score: -179.0   memory length: 2000   epsilon: 0.9559974822731252\n",
      "episode: 175   score: -216.0   memory length: 2000   epsilon: 0.948854321567258\n",
      "episode: 200   score: -245.0   memory length: 2000   epsilon: 0.9417645341666034\n",
      "episode: 225   score: -197.0   memory length: 2000   epsilon: 0.9347277212687504\n",
      "episode: 250   score: -187.0   memory length: 2000   epsilon: 0.927743487051118\n",
      "episode: 275   score: 54.0   memory length: 2000   epsilon: 0.9208114386486902\n",
      "episode: 300   score: -354.0   memory length: 2000   epsilon: 0.9139311861319164\n",
      "episode: 325   score: -174.0   memory length: 2000   epsilon: 0.9071023424847783\n",
      "episode: 350   score: 56.0   memory length: 2000   epsilon: 0.9003245235830204\n",
      "episode: 375   score: -99.0   memory length: 2000   epsilon: 0.8935973481725422\n",
      "episode: 400   score: -175.0   memory length: 2000   epsilon: 0.8869204378479532\n",
      "episode: 425   score: -18.0   memory length: 2000   epsilon: 0.880293417031287\n",
      "episode: 450   score: 207.0   memory length: 2000   epsilon: 0.8737159129508754\n",
      "episode: 475   score: -21.0   memory length: 2000   epsilon: 0.8671875556203794\n",
      "episode: 500   score: -411.0   memory length: 2000   epsilon: 0.860707977817978\n",
      "episode: 525   score: -136.0   memory length: 2000   epsilon: 0.8542768150657114\n",
      "episode: 550   score: 42.0   memory length: 2000   epsilon: 0.8478937056089788\n",
      "episode: 575   score: -133.0   memory length: 2000   epsilon: 0.8415582903961905\n",
      "episode: 600   score: 111.0   memory length: 2000   epsilon: 0.8352702130585699\n",
      "episode: 625   score: -32.0   memory length: 2000   epsilon: 0.8290291198901092\n",
      "episode: 650   score: -315.0   memory length: 2000   epsilon: 0.8228346598276718\n",
      "episode: 675   score: 67.0   memory length: 2000   epsilon: 0.816686484431246\n",
      "episode: 700   score: -138.0   memory length: 2000   epsilon: 0.8105842478643446\n",
      "episode: 725   score: -196.0   memory length: 2000   epsilon: 0.8045276068745518\n",
      "episode: 750   score: 119.0   memory length: 2000   epsilon: 0.7985162207742149\n",
      "episode: 775   score: -215.0   memory length: 2000   epsilon: 0.7925497514212807\n",
      "episode: 800   score: 131.0   memory length: 2000   epsilon: 0.7866278632002749\n",
      "episode: 825   score: 214.0   memory length: 2000   epsilon: 0.7807502230034236\n",
      "episode: 850   score: 93.0   memory length: 2000   epsilon: 0.774916500211916\n",
      "episode: 875   score: -87.0   memory length: 2000   epsilon: 0.7691263666773068\n",
      "episode: 900   score: 161.0   memory length: 2000   epsilon: 0.7633794967030584\n",
      "episode: 925   score: 117.0   memory length: 2000   epsilon: 0.7576755670262189\n",
      "episode: 950   score: 130.0   memory length: 2000   epsilon: 0.75201425679924\n",
      "episode: 975   score: 151.0   memory length: 2000   epsilon: 0.7463952475719293\n",
      "episode: 1000   score: 13.0   memory length: 2000   epsilon: 0.7408182232735356\n",
      "episode: 1025   score: 228.0   memory length: 2000   epsilon: 0.7352828701949721\n",
      "episode: 1050   score: -83.0   memory length: 2000   epsilon: 0.7297888769711681\n",
      "episode: 1075   score: 182.0   memory length: 2000   epsilon: 0.7243359345635565\n",
      "episode: 1100   score: -81.0   memory length: 2000   epsilon: 0.7189237362426889\n"
     ]
    }
   ],
   "source": [
    "Episodes = 10000\n",
    "for episode in range(0,Episodes):\n",
    "    \n",
    "    # tracking total rewards, step count\n",
    "    tot_reward = 0\n",
    "    step_count = 0\n",
    "    state = env.reset()\n",
    "    terminal_state = False\n",
    "    \n",
    "    while not terminal_state:\n",
    "        \n",
    "\n",
    "        action, epsilon = agent.get_action(state, episode)\n",
    "        reward = env.reward_func(state, action, Time_matrix)\n",
    "        \n",
    "        next_state, terminal_state = env.next_state_func(state, action, Time_matrix)\n",
    "\n",
    "        # save the sample <s, a, r, s'> to the replay memory\n",
    "        agent.append_sample(state, action, reward, next_state, terminal_state)\n",
    "        \n",
    "        # every time step do the training\n",
    "        agent.train_model()\n",
    "        tot_reward += reward\n",
    "        state = next_state\n",
    "        step_count += 1\n",
    "        \n",
    "        # Store the rewards\n",
    "        if terminal_state and episode % 25 ==0:\n",
    "            avg_reward.append(tot_reward/step_count)\n",
    "            total_reward.append(tot_reward)\n",
    "            print(\"episode:\", episode, \"  score:\", tot_reward, \"  memory length:\",\n",
    "                      len(agent.memory), \"  epsilon:\", epsilon)\n",
    "    \n",
    "    if episode % 200 == 0:\n",
    "            agent.save(\"./cab_driver.h5\")\n",
    "\n",
    "    if episode % 25 == 0:   #every 2000th episode\n",
    "        save_obj(avg_reward,'Rewards')   \n",
    "        save_tracking_states()\n",
    "        save_obj(states_track,'States_tracked')   \n",
    "        \n",
    "    \n",
    "    if episode % 10000 ==0 and episode !=0:\n",
    "        plt.plot(list(range(len(avg_reward))), avg_reward)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting average rewards\n",
    "# x-values = 10000 episodes tracked after every 25th episode\n",
    "plt.plot(list(range(len(avg_reward))), avg_reward)\n",
    "plt.ylabel(\"Average Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting total rewards\n",
    "plt.plot(list(range(len(total_reward))), total_reward)\n",
    "plt.ylabel(\"Total reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition behind  total expected reward in an episode\n",
    "\n",
    "![image.png](attachment:image.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Q-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "\n",
    "xaxis = np.asarray(range(len(states_track[(3,0,2)][(3,1)])))\n",
    "plt.subplot(241)\n",
    "plt.plot(xaxis,np.asarray(states_track[(3,0,2)][(3,1)]))\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(len(states_track[(1,6,3)][(2,3)])))\n",
    "plt.subplot(242)\n",
    "plt.plot(xaxis,np.asarray(states_track[(1,6,3)][(2,3)]))\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(len(states_track[(2,2,2)][(3,2)])))\n",
    "plt.subplot(243)\n",
    "plt.plot(xaxis,np.asarray(states_track[(2,2,2)][(3,2)]))\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(len(states_track[(3,10,6)][(3,4)])))\n",
    "plt.subplot(244)\n",
    "plt.plot(xaxis,np.asarray(states_track[(3,10,6)][(3,4)]))\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(len(states_track[(0,20,3)][(1,4)])))\n",
    "plt.subplot(245)\n",
    "plt.plot(xaxis,np.asarray(states_track[(0,20,3)][(1,4)]))\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(241)\n",
    "plt.plot(xaxis,np.asarray(states_track[(3,0,2)][(3,1)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(242)\n",
    "plt.plot(xaxis,np.asarray(states_track[(1,6,3)][(2,3)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(243)\n",
    "plt.plot(xaxis,np.asarray(states_track[(2,2,2)][(3,2)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(244)\n",
    "plt.plot(xaxis,np.asarray(states_track[(3,10,6)][(3,4)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show\n",
    "\n",
    "xaxis = np.asarray(range(500))\n",
    "plt.subplot(245)\n",
    "plt.plot(xaxis,np.asarray(states_track[(0,20,3)][(1,4)])[-500:])\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting Q-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3,0,2), # (0, 10, 5)\n",
    "\n",
    "state_encod = env.state_encod_arch1([3,0,2])\n",
    "state_encod = np.reshape(state_encod, [1, agent.state_size])\n",
    "prediction = agent.model.predict(state_encod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for i,j in enumerate(actions):\n",
    "    dict[tuple(j)]=prediction[0][i]\n",
    "    \n",
    "print(dict)\n",
    "print(max(dict,key=dict.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_matrix[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
